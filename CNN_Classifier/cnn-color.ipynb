{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "from tensorflow.keras import datasets, layers, models, regularizers, initializers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.io import imshow\n",
    "from skimage.transform import rotate\n",
    "from skimage.filters.edges import convolve\n",
    "\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "np.random.seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test_labels.csv')\n",
    "df_train = pd.read_csv('data/train_labels.csv')\n",
    "\n",
    "bw_loaded = np.load('data/color_images.npz')\n",
    "X_train= bw_loaded['a']\n",
    "X_test = bw_loaded['b']\n",
    "\n",
    "X_test = X_test.reshape(-1,80,60,3)\n",
    "X_train = X_train.reshape(-1,80,60,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_functions import pick_ylabels, multi_index_counts, test_counts_by_cat, train_counts_by_cat, category_codes, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_ylabels(column):\n",
    "    y_train = df_train[column].copy().astype('category').cat.codes\n",
    "    y_test = df_test[column].copy().astype('category').cat.codes\n",
    "    return (y_train.values, y_test.values)\n",
    "def multi_index_counts(col, col2):\n",
    "    counts = df_test.groupby([col, col2]).count().id\n",
    "    return counts\n",
    "\n",
    "def category_codes(column):\n",
    "    _, ytest = pick_ylabels(column)\n",
    "    cat_codes = {}\n",
    "    cat_code_list = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = i\n",
    "        t = df_test[column].value_counts().index[i]\n",
    "        cat_codes[s] = t\n",
    "#         cat_code_list.append([s, t])\n",
    "\n",
    "#     for key in sorted(cat_codes):\n",
    "#         print(\"%s: %s\" % (key, cat_codes[key]))\n",
    "    return cat_codes\n",
    "\n",
    "def test_counts_by_cat(column):\n",
    "    _, ytest = pick_ylabels(column)\n",
    "    test_counts_dict = {}\n",
    "    test_counts = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = df_test[column].value_counts().values[i]\n",
    "        t = df_test[column].value_counts().index[i]\n",
    "        test_counts_dict[t] = s\n",
    "        test_counts.append([t, s])\n",
    "#     for i in sorted(test_counts):\n",
    "#         print(\"%s: %s\" % (test_counts[0], test_counts[1]))\n",
    "    return test_counts\n",
    "\n",
    "def train_counts_by_cat(column):\n",
    "    y_train = pick_ylabels(column)\n",
    "    train_counts_dict = {}\n",
    "    train_counts = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = df_train[column].value_counts().values[i]\n",
    "        t = df_train[column].value_counts().index[i]\n",
    "        train_counts_dict[t] = s\n",
    "        train_counts.append([t, s])\n",
    "#     for i in sorted(test_counts):\n",
    "#         print(\"%s: %s\" % (test_counts[0], test_counts[1]))\n",
    "    return train_counts\n",
    "\n",
    "def class_weights(column):\n",
    "    train_counts = train_counts_by_cat(column)\n",
    "    counts_list = []\n",
    "    ratio_list = []\n",
    "    ratio_dict = {}\n",
    "    for x in test_counts:\n",
    "        counts_list.append(x[1])\n",
    "    #print(counts_list)\n",
    "    z = sum(counts_list)\n",
    "    for x in counts_list:\n",
    "        if np.round(x/z, 3) ==0:\n",
    "            ratio_list.append(.001)\n",
    "        else: \n",
    "            ratio_list.append(np.round(x/z, 2))\n",
    "    for k, v in enumerate(ratio_list):\n",
    "        ratio_dict[k] = v\n",
    "    return ratio_dict\n",
    "\n",
    "def model_results(model, column):\n",
    "    yhat = model.predict(X_test)\n",
    "    _ , ytest = pick_ylabels(column)\n",
    "    accuracy = accuracy_score(ytest, yhat)\n",
    "    print( 'Accuracy Score: ', accuracy )\n",
    "    recall = recall_score(ytest, yhat, average='weighted')\n",
    "    print( 'Recall Score: ', recall)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    wrong_id_list = []\n",
    "    pred_cat_list = []\n",
    "    real_cat_list = []\n",
    "    for row_idx in range(len(ytest)):\n",
    "        if ytest[row_idx]!=yhat[row_idx]:\n",
    "            wrong_id_list.append(row_idx)\n",
    "            pred_cat_list.append(yhat[row_idx])\n",
    "            real_cat_list.append(ytest[row_idx])\n",
    "\n",
    "    arr = np.array([ real_cat_list, pred_cat_list])\n",
    "    arr = arr.transpose()\n",
    "    wrong_df = pd.DataFrame( arr, index= wrong_id_list, columns = ['actual', 'predicted'] )\n",
    "    return (accuracy, recall, wrong_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0     5745\n",
       " 18    3127\n",
       " 1     2801\n",
       " 3     2752\n",
       " 8     2563\n",
       " 15    1754\n",
       " 7     1323\n",
       " 13    1073\n",
       " 14    1031\n",
       " 11     923\n",
       " 5      784\n",
       " 12     352\n",
       " 17     317\n",
       " 19     290\n",
       " 10     251\n",
       " 16     179\n",
       " 2       65\n",
       " 4       62\n",
       " 9       31\n",
       "-1       12\n",
       " 6        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train[df_train.masterCategory=='Apparel']\n",
    "train_idx = list(train.index)\n",
    "X_train_app = X_train[train_idx]\n",
    "\n",
    "test = df_test[df_test.masterCategory=='Apparel']\n",
    "test_idx = list(test.index)\n",
    "X_test_app = X_test[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train0 = df_train.baseColour.copy().astype('category').cat.codes\n",
    "y_test0 = df_test.baseColour.copy().astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train0)\n",
    "y_test = to_categorical(y_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25439, 20)\n",
      "(6440, 19)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_sub = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_sub.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_sub.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_sub.add(Dropout(0.2))\n",
    "\n",
    "cnn_sub.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_sub.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_sub.add(Dropout(0.25))\n",
    "\n",
    "cnn_sub.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_sub.add(Dropout(0.4))\n",
    "\n",
    "cnn_sub.add(Flatten())\n",
    "\n",
    "cnn_sub.add(Dense(128, activation='relu'))\n",
    "cnn_sub.add(Dropout(0.3))\n",
    "cnn_sub.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 2,977,158\n",
      "Trainable params: 2,977,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_sub.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sub.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9194 samples, validate on 2619 samples\n",
      "Epoch 1/20\n",
      "9194/9194 [==============================] - 18s 2ms/sample - loss: 4.0289 - acc: 0.7172 - val_loss: 0.4181 - val_acc: 0.8767\n",
      "Epoch 2/20\n",
      "9194/9194 [==============================] - 18s 2ms/sample - loss: 0.4639 - acc: 0.8619 - val_loss: 0.3443 - val_acc: 0.9103\n",
      "Epoch 3/20\n",
      "9194/9194 [==============================] - 16s 2ms/sample - loss: 0.3804 - acc: 0.8875 - val_loss: 0.3128 - val_acc: 0.9213\n",
      "Epoch 4/20\n",
      "8384/9194 [==========================>...] - ETA: 1s - loss: 0.3152 - acc: 0.9055"
     ]
    }
   ],
   "source": [
    "cnn_sub.fit(X_train_app, y_train, epochs=20, validation_data=(X_test_app, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_sub.to_json()\n",
    "with open(\"cnn_sub.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8022,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes = model.predict_classes(X_test)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = np.nonzero(predicted_classes==y_true)[0]\n",
    "incorrect = np.nonzero(predicted_classes!=y_true)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.88      0.84      0.86      2035\n",
      "     Class 1       0.93      0.95      0.94      4431\n",
      "     Class 2       0.97      0.94      0.95      1827\n",
      "     Class 3       0.72      0.75      0.74       478\n",
      "\n",
      "    accuracy                           0.91      8771\n",
      "   macro avg       0.87      0.87      0.87      8771\n",
      "weighted avg       0.91      0.91      0.91      8771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(4)]\n",
    "print(classification_report(y_true, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30791, 80, 60, 1), (30791, 7))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(model, column):\n",
    "    yhat = model.predict(X_test)\n",
    "    _ , ytest = pick_ylabels(column)\n",
    "    accuracy = accuracy_score(ytest, yhat)\n",
    "    print( 'Accuracy Score: ', accuracy )\n",
    "    recall = recall_score(ytest, yhat, average='weighted')\n",
    "    print( 'Recall Score: ', recall)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    wrong_id_list = []\n",
    "    pred_cat_list = []\n",
    "    real_cat_list = []\n",
    "    for row_idx in range(len(ytest)):\n",
    "        if ytest[row_idx]!=yhat[row_idx]:\n",
    "            wrong_id_list.append(row_idx)\n",
    "            pred_cat_list.append(yhat[row_idx])\n",
    "            real_cat_list.append(ytest[row_idx])\n",
    "\n",
    "    arr = np.array([ real_cat_list, pred_cat_list])\n",
    "    arr = arr.transpose()\n",
    "    wrong_df = pd.DataFrame( arr, index= wrong_id_list, columns = ['actual', 'predicted'] )\n",
    "    return (accuracy, recall, wrong_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
