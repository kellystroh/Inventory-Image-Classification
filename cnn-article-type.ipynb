{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "from tensorflow.keras import datasets, layers, models, regularizers, initializers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.io import imshow\n",
    "from skimage.transform import rotate\n",
    "from skimage.filters.edges import convolve\n",
    "\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "np.random.seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test_labels.csv')\n",
    "df_train = pd.read_csv('data/train_labels.csv')\n",
    "\n",
    "bw_loaded = np.load('data/bw_images.npz')\n",
    "X_train= bw_loaded['a']\n",
    "X_test = bw_loaded['b']\n",
    "\n",
    "X_test = X_test.reshape(-1,80,60,1)\n",
    "X_train = X_train.reshape(-1,80,60,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_functions import pick_ylabels, multi_index_counts, test_counts_by_cat, train_counts_by_cat, category_codes, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_ylabels(column):\n",
    "    y_train = df_train[column].copy().astype('category').cat.codes\n",
    "    y_test = df_test[column].copy().astype('category').cat.codes\n",
    "    return (y_train.values, y_test.values)\n",
    "def multi_index_counts(col, col2):\n",
    "    counts = df_test.groupby([col, col2]).count().id\n",
    "    return counts\n",
    "\n",
    "def category_codes(column):\n",
    "    _, ytest = pick_ylabels(column)\n",
    "    cat_codes = {}\n",
    "    cat_code_list = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = i\n",
    "        t = df_test[column].value_counts().index[i]\n",
    "        cat_codes[s] = t\n",
    "#         cat_code_list.append([s, t])\n",
    "\n",
    "#     for key in sorted(cat_codes):\n",
    "#         print(\"%s: %s\" % (key, cat_codes[key]))\n",
    "    return cat_codes\n",
    "\n",
    "def test_counts_by_cat(column):\n",
    "    _, ytest = pick_ylabels(column)\n",
    "    test_counts_dict = {}\n",
    "    test_counts = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = df_test[column].value_counts().values[i]\n",
    "        t = df_test[column].value_counts().index[i]\n",
    "        test_counts_dict[t] = s\n",
    "        test_counts.append([t, s])\n",
    "#     for i in sorted(test_counts):\n",
    "#         print(\"%s: %s\" % (test_counts[0], test_counts[1]))\n",
    "    return test_counts\n",
    "\n",
    "def train_counts_by_cat(column):\n",
    "    y_train = pick_ylabels(column)\n",
    "    train_counts_dict = {}\n",
    "    train_counts = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = df_train[column].value_counts().values[i]\n",
    "        t = df_train[column].value_counts().index[i]\n",
    "        train_counts_dict[t] = s\n",
    "        train_counts.append([t, s])\n",
    "#     for i in sorted(test_counts):\n",
    "#         print(\"%s: %s\" % (test_counts[0], test_counts[1]))\n",
    "    return train_counts\n",
    "\n",
    "def class_weights(column):\n",
    "    train_counts = train_counts_by_cat(column)\n",
    "    counts_list = []\n",
    "    ratio_list = []\n",
    "    ratio_dict = {}\n",
    "    for x in test_counts:\n",
    "        counts_list.append(x[1])\n",
    "    #print(counts_list)\n",
    "    z = sum(counts_list)\n",
    "    for x in counts_list:\n",
    "        if np.round(x/z, 3) ==0:\n",
    "            ratio_list.append(.001)\n",
    "        else: \n",
    "            ratio_list.append(np.round(x/z, 2))\n",
    "    for k, v in enumerate(ratio_list):\n",
    "        ratio_dict[k] = v\n",
    "    return ratio_dict\n",
    "\n",
    "def model_results(model, column):\n",
    "    yhat = model.predict(X_test)\n",
    "    _ , ytest = pick_ylabels(column)\n",
    "    accuracy = accuracy_score(ytest, yhat)\n",
    "    print( 'Accuracy Score: ', accuracy )\n",
    "    recall = recall_score(ytest, yhat, average='weighted')\n",
    "    print( 'Recall Score: ', recall)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    wrong_id_list = []\n",
    "    pred_cat_list = []\n",
    "    real_cat_list = []\n",
    "    for row_idx in range(len(ytest)):\n",
    "        if ytest[row_idx]!=yhat[row_idx]:\n",
    "            wrong_id_list.append(row_idx)\n",
    "            pred_cat_list.append(yhat[row_idx])\n",
    "            real_cat_list.append(ytest[row_idx])\n",
    "\n",
    "    arr = np.array([ real_cat_list, pred_cat_list])\n",
    "    arr = arr.transpose()\n",
    "    wrong_df = pd.DataFrame( arr, index= wrong_id_list, columns = ['actual', 'predicted'] )\n",
    "    return (accuracy, recall, wrong_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Article Types for Apparel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = df_train[df_train.masterCategory=='Apparel']\n",
    "app_train_idx = list(app_train.index)\n",
    "X_train_app = X_train[app_train_idx]\n",
    "\n",
    "app_test = df_test[df_test.masterCategory=='Apparel']\n",
    "app_test_idx = list(app_test.index)\n",
    "X_test_app = X_test[app_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train0 = app_train.articleType.copy().astype('category').cat.codes\n",
    "y_test0 = app_test.articleType.copy().astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train0)\n",
    "y_test = to_categorical(y_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10394, 33)\n",
      "(2603, 33)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_sub = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_sub.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_sub.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_sub.add(Dropout(0.25))\n",
    "\n",
    "# cnn_sub.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "# cnn_sub.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# cnn_sub.add(Dropout(0.25))\n",
    "\n",
    "cnn_sub.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_sub.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_sub.add(Dropout(0.25))\n",
    "\n",
    "cnn_sub.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "# cnn_sub.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_sub.add(Dropout(0.4))\n",
    "\n",
    "cnn_sub.add(Flatten())\n",
    "\n",
    "# cnn_sub.add(Dense(512, activation='relu'))\n",
    "# cnn_sub.add(Dropout(0.5))\n",
    "cnn_sub.add(Dense(128, activation='relu'))\n",
    "cnn_sub.add(Dropout(0.5))\n",
    "cnn_sub.add(Dense(33, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sub.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sub.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10394 samples, validate on 2603 samples\n",
      "Epoch 1/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 3.8525 - acc: 0.1992 - val_loss: 3.1103 - val_acc: 0.2313\n",
      "Epoch 2/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 2.5922 - acc: 0.2862 - val_loss: 2.4022 - val_acc: 0.4368\n",
      "Epoch 3/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 2.0169 - acc: 0.4506 - val_loss: 1.5631 - val_acc: 0.5674\n",
      "Epoch 4/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 1.6526 - acc: 0.5413 - val_loss: 1.3249 - val_acc: 0.6431\n",
      "Epoch 5/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 1.4487 - acc: 0.5914 - val_loss: 1.1177 - val_acc: 0.6677\n",
      "Epoch 6/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 1.3263 - acc: 0.6234 - val_loss: 1.0581 - val_acc: 0.6934\n",
      "Epoch 7/20\n",
      "10394/10394 [==============================] - 12s 1ms/sample - loss: 1.2311 - acc: 0.6471 - val_loss: 0.9617 - val_acc: 0.7130\n",
      "Epoch 8/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 1.1445 - acc: 0.6715 - val_loss: 0.8837 - val_acc: 0.7257\n",
      "Epoch 9/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 1.0986 - acc: 0.6858 - val_loss: 0.8627 - val_acc: 0.7368\n",
      "Epoch 10/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 1.0542 - acc: 0.6967 - val_loss: 0.8538 - val_acc: 0.7584\n",
      "Epoch 11/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 1.0287 - acc: 0.7014 - val_loss: 0.8793 - val_acc: 0.7418\n",
      "Epoch 12/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 0.9883 - acc: 0.7108 - val_loss: 0.7742 - val_acc: 0.7572\n",
      "Epoch 13/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 0.9638 - acc: 0.7171 - val_loss: 0.7408 - val_acc: 0.7653\n",
      "Epoch 14/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 0.9378 - acc: 0.7274 - val_loss: 0.7770 - val_acc: 0.7641\n",
      "Epoch 15/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 0.9024 - acc: 0.7328 - val_loss: 0.7093 - val_acc: 0.7841\n",
      "Epoch 16/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 0.8890 - acc: 0.7348 - val_loss: 0.7216 - val_acc: 0.7672\n",
      "Epoch 17/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 0.8615 - acc: 0.7464 - val_loss: 0.7651 - val_acc: 0.7783\n",
      "Epoch 18/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 0.8730 - acc: 0.7414 - val_loss: 0.7027 - val_acc: 0.7914\n",
      "Epoch 19/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 0.8304 - acc: 0.7540 - val_loss: 0.6713 - val_acc: 0.7860\n",
      "Epoch 20/20\n",
      "10394/10394 [==============================] - 13s 1ms/sample - loss: 0.8256 - acc: 0.7568 - val_loss: 0.6630 - val_acc: 0.7922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feb002fecf8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_sub.fit(X_train_app, y_train, epochs=20, validation_data=(X_test_app, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_sub.to_json()\n",
    "with open(\"cnn_apparel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes = cnn_sub.predict_classes(X_test_app)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = np.nonzero(predicted_classes==y_true)[0]\n",
    "incorrect = np.nonzero(predicted_classes!=y_true)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 5, ..., 0, 5, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.95      0.98      0.96       368\n",
      "     Class 1       0.96      0.91      0.93       347\n",
      "     Class 2       0.90      0.55      0.68        96\n",
      "     Class 3       0.95      0.98      0.96        82\n",
      "     Class 4       0.98      0.93      0.95       135\n",
      "     Class 5       0.96      0.99      0.98      1591\n",
      "\n",
      "    accuracy                           0.96      2619\n",
      "   macro avg       0.95      0.89      0.91      2619\n",
      "weighted avg       0.96      0.96      0.96      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(6)]\n",
    "print(classification_report(y_true, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sub-Categories for Accessories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5586, 6)\n",
      "(1656, 6)\n"
     ]
    }
   ],
   "source": [
    "acc_train = df_train[df_train.masterCategory=='Accessories']\n",
    "acc_train_idx = list(acc_train.index)\n",
    "X_train_acc = X_train[acc_train_idx]\n",
    "\n",
    "acc_test = df_test[df_test.masterCategory=='Accessories']\n",
    "acc_test_idx = list(acc_test.index)\n",
    "X_test_acc = X_test[acc_test_idx]\n",
    "\n",
    "y_train_acc0 = acc_train.subCategory.copy().astype('category').cat.codes\n",
    "y_test_acc0 = acc_test.subCategory.copy().astype('category').cat.codes\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_acc = to_categorical(y_train_acc0)\n",
    "y_test_acc = to_categorical(y_test_acc0)\n",
    "\n",
    "print(y_train_acc.shape)\n",
    "print(y_test_acc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_acc = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_acc.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_acc.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_acc.add(Dropout(0.2))\n",
    "\n",
    "cnn_acc.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_acc.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_acc.add(Dropout(0.25))\n",
    "\n",
    "cnn_acc.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_acc.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "cnn_acc.add(Flatten())\n",
    "\n",
    "cnn_acc.add(Dense(128, activation='relu'))\n",
    "cnn_acc.add(Dropout(0.3))\n",
    "cnn_acc.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 2,977,158\n",
      "Trainable params: 2,977,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_acc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_acc.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5586 samples, validate on 1656 samples\n",
      "Epoch 1/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 5.3784 - acc: 0.7053 - val_loss: 0.2950 - val_acc: 0.8877\n",
      "Epoch 2/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.3736 - acc: 0.8813 - val_loss: 0.1463 - val_acc: 0.9589\n",
      "Epoch 3/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.2637 - acc: 0.9239 - val_loss: 0.2154 - val_acc: 0.9185\n",
      "Epoch 4/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.2196 - acc: 0.9338 - val_loss: 0.1077 - val_acc: 0.9716\n",
      "Epoch 5/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1816 - acc: 0.9440 - val_loss: 0.1520 - val_acc: 0.9662\n",
      "Epoch 6/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1455 - acc: 0.9552 - val_loss: 0.1314 - val_acc: 0.9668\n",
      "Epoch 7/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1347 - acc: 0.9603 - val_loss: 0.0842 - val_acc: 0.9819\n",
      "Epoch 8/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1180 - acc: 0.9662 - val_loss: 0.0910 - val_acc: 0.9789\n",
      "Epoch 9/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.0951 - acc: 0.9735 - val_loss: 0.0659 - val_acc: 0.9873\n",
      "Epoch 10/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.0908 - acc: 0.9701 - val_loss: 0.0688 - val_acc: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efe905dee48>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_acc.fit(X_train_acc, y_train_acc, epochs=10, validation_data=(X_test_acc, y_test_acc), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_acc = y_test_acc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes_acc = cnn_acc.predict_classes(X_test_acc)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = (predicted_classes_acc ==y_true_acc).to_numpy().nonzero()[0]\n",
    "incorrect = (predicted_classes_acc !=y_true_acc).to_numpy().nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.97      0.98       597\n",
      "     Class 1       1.00      1.00      1.00       213\n",
      "     Class 2       1.00      0.79      0.88        56\n",
      "     Class 3       0.93      0.98      0.96       230\n",
      "     Class 4       1.00      0.98      0.99        50\n",
      "     Class 5       0.97      0.99      0.98       510\n",
      "\n",
      "    accuracy                           0.98      1656\n",
      "   macro avg       0.98      0.95      0.96      1656\n",
      "weighted avg       0.98      0.98      0.98      1656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names_acc = [\"Class {}\".format(i) for i in range(6)]\n",
    "print(classification_report(y_true_acc, predicted_classes_acc, target_names=target_names_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_acc.to_json()\n",
    "with open(\"cnn_accessories.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sub-Categories for Footwear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6296, 3)\n",
      "(1796, 3)\n"
     ]
    }
   ],
   "source": [
    "fw_train = df_train[df_train.masterCategory=='Footwear']\n",
    "fw_train_idx = list(fw_train.index)\n",
    "X_train_fw = X_train[fw_train_idx]\n",
    "\n",
    "fw_test = df_test[df_test.masterCategory=='Footwear']\n",
    "fw_test_idx = list(fw_test.index)\n",
    "X_test_fw = X_test[fw_test_idx]\n",
    "\n",
    "y_train_fw0 = fw_train.subCategory.copy().astype('category').cat.codes\n",
    "y_test_fw0 = fw_test.subCategory.copy().astype('category').cat.codes\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_fw = to_categorical(y_train_fw0)\n",
    "y_test_fw = to_categorical(y_test_fw0)\n",
    "\n",
    "print(y_train_fw.shape)\n",
    "print(y_test_fw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fw = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_fw.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_fw.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_fw.add(Dropout(0.25))\n",
    "\n",
    "cnn_fw.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_fw.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_fw.add(Dropout(0.25))\n",
    "\n",
    "cnn_fw.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_fw.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_fw.add(Dropout(0.25))\n",
    "\n",
    "cnn_fw.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_fw.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "cnn_fw.add(Flatten())\n",
    "cnn_fw.add(Dense(512, activation='relu'))\n",
    "cnn_fw.add(Dropout(0.5))\n",
    "cnn_fw.add(Dense(128, activation='relu'))\n",
    "cnn_fw.add(Dropout(0.5))\n",
    "cnn_fw.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,976,771\n",
      "Trainable params: 2,976,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_fw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fw.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6296 samples, validate on 1796 samples\n",
      "Epoch 1/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.2411 - acc: 0.9096 - val_loss: 0.2692 - val_acc: 0.9059\n",
      "Epoch 2/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.2430 - acc: 0.9142 - val_loss: 0.2402 - val_acc: 0.9209\n",
      "Epoch 3/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.2186 - acc: 0.9196 - val_loss: 0.2267 - val_acc: 0.9259\n",
      "Epoch 4/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.2075 - acc: 0.9187 - val_loss: 0.2224 - val_acc: 0.9287\n",
      "Epoch 5/20\n",
      "1152/6296 [====>.........................] - ETA: 6s - loss: 0.1787 - acc: 0.9297"
     ]
    }
   ],
   "source": [
    "cnn_fw.fit(X_train_fw, y_train_fw, epochs=20, validation_data=(X_test_fw, y_test_fw), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_fw = y_test_fw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes_fw = cnn_fw.predict_classes(X_test_fw)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = (predicted_classes_fw ==y_true_fw).to_numpy().nonzero()[0]\n",
    "incorrect = (predicted_classes_fw !=y_true_fw).to_numpy().nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.97      0.98       597\n",
      "     Class 1       1.00      1.00      1.00       213\n",
      "     Class 2       1.00      0.79      0.88        56\n",
      "     Class 3       0.93      0.98      0.96       230\n",
      "     Class 4       1.00      0.98      0.99        50\n",
      "     Class 5       0.97      0.99      0.98       510\n",
      "\n",
      "    accuracy                           0.98      1656\n",
      "   macro avg       0.98      0.95      0.96      1656\n",
      "weighted avg       0.98      0.98      0.98      1656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names_fw = [\"Class {}\".format(i) for i in range(3)]\n",
    "print(classification_report(y_true_fw, predicted_classes_fw, target_names=target_names_fw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_fw.to_json()\n",
    "with open(\"cnn_footwear.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sub-Categories for Personal Care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6296, 3)\n",
      "(1796, 3)\n"
     ]
    }
   ],
   "source": [
    "pc_train = df_train[df_train.masterCategory=='Personal Care']\n",
    "pc_train_idx = list(pc_train.index)\n",
    "X_train_pc = X_train[pc_train_idx]\n",
    "\n",
    "pc_test = df_test[df_test.masterCategory=='Personal Care']\n",
    "pc_test_idx = list(pc_test.index)\n",
    "X_test_pc = X_test[pc_test_idx]\n",
    "\n",
    "y_train_pc0 = fw_train.subCategory.copy().astype('category').cat.codes\n",
    "y_test_pc0 = fw_test.subCategory.copy().astype('category').cat.codes\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_pc = to_categorical(y_train_pc0)\n",
    "y_test_pc = to_categorical(y_test_pc0)\n",
    "\n",
    "print(y_train_pc.shape)\n",
    "print(y_test_pc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pc = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_pc.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_pc.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_pc.add(Dropout(0.2)\n",
    "\n",
    "cnn_pc.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_pc.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_pc.add(Dropout(0.25)\n",
    "\n",
    "cnn_pc.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_pc.add(Dropout(0.4)\n",
    "           \n",
    "cnn_pc.add(Flatten()\n",
    "           \n",
    "cnn_pc.add(Dense(128, activation='relu'))\n",
    "cnn_pc.add(Dropout(0.3))\n",
    "cnn_pc.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,976,771\n",
      "Trainable params: 2,976,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_fw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fw.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6296 samples, validate on 1796 samples\n",
      "Epoch 1/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 5.0477 - acc: 0.7851 - val_loss: 0.7035 - val_acc: 0.7973\n",
      "Epoch 2/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.5417 - acc: 0.8135 - val_loss: 0.3989 - val_acc: 0.8190\n",
      "Epoch 3/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.4569 - acc: 0.8313 - val_loss: 0.3964 - val_acc: 0.8330\n",
      "Epoch 4/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.3950 - acc: 0.8523 - val_loss: 0.3420 - val_acc: 0.8803\n",
      "Epoch 5/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.3457 - acc: 0.8774 - val_loss: 0.3733 - val_acc: 0.8469\n",
      "Epoch 6/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.3220 - acc: 0.8809 - val_loss: 0.3126 - val_acc: 0.8959\n",
      "Epoch 7/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.2981 - acc: 0.8939 - val_loss: 0.2801 - val_acc: 0.9087\n",
      "Epoch 8/10\n",
      "2080/6296 [========>.....................] - ETA: 5s - loss: 0.3045 - acc: 0.8990"
     ]
    }
   ],
   "source": [
    "cnn_fw.fit(X_train_fw, y_train_fw, epochs=10, validation_data=(X_test_fw, y_test_fw), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_fw = y_test_fw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes_fw = cnn_fw.predict_classes(X_test_fw)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = (predicted_classes_fw ==y_true_fw).to_numpy().nonzero()[0]\n",
    "incorrect = (predicted_classes_fw !=y_true_fw).to_numpy().nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.97      0.98       597\n",
      "     Class 1       1.00      1.00      1.00       213\n",
      "     Class 2       1.00      0.79      0.88        56\n",
      "     Class 3       0.93      0.98      0.96       230\n",
      "     Class 4       1.00      0.98      0.99        50\n",
      "     Class 5       0.97      0.99      0.98       510\n",
      "\n",
      "    accuracy                           0.98      1656\n",
      "   macro avg       0.98      0.95      0.96      1656\n",
      "weighted avg       0.98      0.98      0.98      1656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names_fw = [\"Class {}\".format(i) for i in range(3)]\n",
    "print(classification_report(y_true_fw, predicted_classes_fw, target_names=target_names_fw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_fw.to_json()\n",
    "with open(\"cnn_footwear.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
