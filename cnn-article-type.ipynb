{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "from tensorflow.keras import datasets, layers, models, regularizers, initializers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.io import imshow\n",
    "from skimage.transform import rotate\n",
    "from skimage.filters.edges import convolve\n",
    "\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "np.random.seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test_labels.csv')\n",
    "df_train = pd.read_csv('data/train_labels.csv')\n",
    "\n",
    "bw_loaded = np.load('data/bw_images.npz')\n",
    "X_train= bw_loaded['a']\n",
    "X_test = bw_loaded['b']\n",
    "\n",
    "X_test = X_test.reshape(-1,80,60,1)\n",
    "X_train = X_train.reshape(-1,80,60,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_functions import pick_ylabels, multi_index_counts, test_counts_by_cat, train_counts_by_cat, category_codes, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_ylabels(column):\n",
    "    y_train = df_train[column].copy().astype('category').cat.codes\n",
    "    y_test = df_test[column].copy().astype('category').cat.codes\n",
    "    return (y_train.values, y_test.values)\n",
    "def multi_index_counts(col, col2):\n",
    "    counts = df_test.groupby([col, col2]).count().id\n",
    "    return counts\n",
    "\n",
    "def category_codes(column):\n",
    "    _, ytest = pick_ylabels(column)\n",
    "    cat_codes = {}\n",
    "    cat_code_list = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = i\n",
    "        t = df_test[column].value_counts().index[i]\n",
    "        cat_codes[s] = t\n",
    "#         cat_code_list.append([s, t])\n",
    "\n",
    "#     for key in sorted(cat_codes):\n",
    "#         print(\"%s: %s\" % (key, cat_codes[key]))\n",
    "    return cat_codes\n",
    "\n",
    "def test_counts_by_cat(column):\n",
    "    _, ytest = pick_ylabels(column)\n",
    "    test_counts_dict = {}\n",
    "    test_counts = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = df_test[column].value_counts().values[i]\n",
    "        t = df_test[column].value_counts().index[i]\n",
    "        test_counts_dict[t] = s\n",
    "        test_counts.append([t, s])\n",
    "#     for i in sorted(test_counts):\n",
    "#         print(\"%s: %s\" % (test_counts[0], test_counts[1]))\n",
    "    return test_counts\n",
    "\n",
    "def train_counts_by_cat(column):\n",
    "    y_train = pick_ylabels(column)\n",
    "    train_counts_dict = {}\n",
    "    train_counts = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = df_train[column].value_counts().values[i]\n",
    "        t = df_train[column].value_counts().index[i]\n",
    "        train_counts_dict[t] = s\n",
    "        train_counts.append([t, s])\n",
    "#     for i in sorted(test_counts):\n",
    "#         print(\"%s: %s\" % (test_counts[0], test_counts[1]))\n",
    "    return train_counts\n",
    "\n",
    "def class_weights(column):\n",
    "    train_counts = train_counts_by_cat(column)\n",
    "    counts_list = []\n",
    "    ratio_list = []\n",
    "    ratio_dict = {}\n",
    "    for x in test_counts:\n",
    "        counts_list.append(x[1])\n",
    "    #print(counts_list)\n",
    "    z = sum(counts_list)\n",
    "    for x in counts_list:\n",
    "        if np.round(x/z, 3) ==0:\n",
    "            ratio_list.append(.001)\n",
    "        else: \n",
    "            ratio_list.append(np.round(x/z, 2))\n",
    "    for k, v in enumerate(ratio_list):\n",
    "        ratio_dict[k] = v\n",
    "    return ratio_dict\n",
    "\n",
    "def model_results(model, column):\n",
    "    yhat = model.predict(X_test)\n",
    "    _ , ytest = pick_ylabels(column)\n",
    "    accuracy = accuracy_score(ytest, yhat)\n",
    "    print( 'Accuracy Score: ', accuracy )\n",
    "    recall = recall_score(ytest, yhat, average='weighted')\n",
    "    print( 'Recall Score: ', recall)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    wrong_id_list = []\n",
    "    pred_cat_list = []\n",
    "    real_cat_list = []\n",
    "    for row_idx in range(len(ytest)):\n",
    "        if ytest[row_idx]!=yhat[row_idx]:\n",
    "            wrong_id_list.append(row_idx)\n",
    "            pred_cat_list.append(yhat[row_idx])\n",
    "            real_cat_list.append(ytest[row_idx])\n",
    "\n",
    "    arr = np.array([ real_cat_list, pred_cat_list])\n",
    "    arr = arr.transpose()\n",
    "    wrong_df = pd.DataFrame( arr, index= wrong_id_list, columns = ['actual', 'predicted'] )\n",
    "    return (accuracy, recall, wrong_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Article Types for Apparel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = df_train[df_train.masterCategory=='Apparel']\n",
    "app_train_idx = list(app_train.index)\n",
    "X_train_app = X_train[app_train_idx]\n",
    "\n",
    "app_test = df_test[df_test.masterCategory=='Apparel']\n",
    "app_test_idx = list(app_test.index)\n",
    "X_test_app = X_test[app_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train0 = app_train.articleType.copy().astype('category').cat.codes\n",
    "y_test0 = app_test.articleType.copy().astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train0)\n",
    "y_test = to_categorical(y_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10394, 33)\n",
      "(2603, 33)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_sub = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_sub.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_sub.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_sub.add(Dropout(0.25))\n",
    "\n",
    "# cnn_sub.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "# cnn_sub.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# cnn_sub.add(Dropout(0.25))\n",
    "\n",
    "cnn_sub.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_sub.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_sub.add(Dropout(0.25))\n",
    "\n",
    "cnn_sub.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "# cnn_sub.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_sub.add(Dropout(0.4))\n",
    "\n",
    "cnn_sub.add(Flatten())\n",
    "\n",
    "# cnn_sub.add(Dense(512, activation='relu'))\n",
    "# cnn_sub.add(Dropout(0.5))\n",
    "cnn_sub.add(Dense(128, activation='relu'))\n",
    "cnn_sub.add(Dropout(0.3))\n",
    "cnn_sub.add(Dense(33, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 33)                4257      \n",
      "=================================================================\n",
      "Total params: 2,980,641\n",
      "Trainable params: 2,980,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_sub.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sub.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10394 samples, validate on 2603 samples\n",
      "Epoch 1/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 4.0015 - acc: 0.3407 - val_loss: 1.5403 - val_acc: 0.5782\n",
      "Epoch 2/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 1.5344 - acc: 0.5787 - val_loss: 1.1887 - val_acc: 0.6443\n",
      "Epoch 3/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 1.2220 - acc: 0.6519 - val_loss: 0.9399 - val_acc: 0.7326\n",
      "Epoch 4/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 1.0473 - acc: 0.6988 - val_loss: 0.8152 - val_acc: 0.7630\n",
      "Epoch 5/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.9262 - acc: 0.7258 - val_loss: 0.7390 - val_acc: 0.7749\n",
      "Epoch 6/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.8584 - acc: 0.7455 - val_loss: 0.7146 - val_acc: 0.7818\n",
      "Epoch 7/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.7787 - acc: 0.7602 - val_loss: 0.6713 - val_acc: 0.7945\n",
      "Epoch 8/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.7324 - acc: 0.7763 - val_loss: 0.6279 - val_acc: 0.8083\n",
      "Epoch 9/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.6922 - acc: 0.7835 - val_loss: 0.6135 - val_acc: 0.8110\n",
      "Epoch 10/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.6549 - acc: 0.7966 - val_loss: 0.6159 - val_acc: 0.8071\n",
      "Epoch 11/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.6459 - acc: 0.8008 - val_loss: 0.6113 - val_acc: 0.8095\n",
      "Epoch 12/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.6049 - acc: 0.8075 - val_loss: 0.5839 - val_acc: 0.8210\n",
      "Epoch 13/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.5772 - acc: 0.8184 - val_loss: 0.5957 - val_acc: 0.8167\n",
      "Epoch 14/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.5706 - acc: 0.8182 - val_loss: 0.5837 - val_acc: 0.8229\n",
      "Epoch 15/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.5316 - acc: 0.8287 - val_loss: 0.5951 - val_acc: 0.8240\n",
      "Epoch 16/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.5201 - acc: 0.8338 - val_loss: 0.6153 - val_acc: 0.8098\n",
      "Epoch 17/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.5322 - acc: 0.8284 - val_loss: 0.5788 - val_acc: 0.8313\n",
      "Epoch 18/50\n",
      "10394/10394 [==============================] - 21s 2ms/sample - loss: 0.4962 - acc: 0.8412 - val_loss: 0.6168 - val_acc: 0.8221\n",
      "Epoch 19/50\n",
      "10394/10394 [==============================] - 19s 2ms/sample - loss: 0.4840 - acc: 0.8469 - val_loss: 0.5938 - val_acc: 0.8252\n",
      "Epoch 20/50\n",
      "10394/10394 [==============================] - 18s 2ms/sample - loss: 0.4717 - acc: 0.8534 - val_loss: 0.5975 - val_acc: 0.8214\n",
      "Epoch 21/50\n",
      "10394/10394 [==============================] - 21s 2ms/sample - loss: 0.4581 - acc: 0.8567 - val_loss: 0.5880 - val_acc: 0.8202\n",
      "Epoch 22/50\n",
      "10394/10394 [==============================] - 21s 2ms/sample - loss: 0.4330 - acc: 0.8594 - val_loss: 0.6356 - val_acc: 0.8244\n",
      "Epoch 23/50\n",
      "10394/10394 [==============================] - 21s 2ms/sample - loss: 0.4481 - acc: 0.8563 - val_loss: 0.6390 - val_acc: 0.8256\n",
      "Epoch 24/50\n",
      "10394/10394 [==============================] - 21s 2ms/sample - loss: 0.4215 - acc: 0.8625 - val_loss: 0.6290 - val_acc: 0.8264\n",
      "Epoch 25/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.4111 - acc: 0.8638 - val_loss: 0.5683 - val_acc: 0.8398\n",
      "Epoch 26/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.4022 - acc: 0.8700 - val_loss: 0.5644 - val_acc: 0.8386\n",
      "Epoch 27/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.3761 - acc: 0.8769 - val_loss: 0.5664 - val_acc: 0.8379\n",
      "Epoch 28/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.3724 - acc: 0.8769 - val_loss: 0.6052 - val_acc: 0.8337\n",
      "Epoch 29/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.3665 - acc: 0.8788 - val_loss: 0.5885 - val_acc: 0.8383\n",
      "Epoch 30/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.3609 - acc: 0.8827 - val_loss: 0.6076 - val_acc: 0.8356\n",
      "Epoch 31/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.3380 - acc: 0.8928 - val_loss: 0.5740 - val_acc: 0.8298\n",
      "Epoch 32/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.3491 - acc: 0.8913 - val_loss: 0.5954 - val_acc: 0.8279\n",
      "Epoch 33/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.3429 - acc: 0.8914 - val_loss: 0.5763 - val_acc: 0.8313\n",
      "Epoch 34/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.3251 - acc: 0.8949 - val_loss: 0.5873 - val_acc: 0.8429\n",
      "Epoch 35/50\n",
      "10394/10394 [==============================] - 14s 1ms/sample - loss: 0.3320 - acc: 0.8934 - val_loss: 0.5871 - val_acc: 0.8375\n",
      "Epoch 36/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.3143 - acc: 0.8994 - val_loss: 0.5954 - val_acc: 0.8321\n",
      "Epoch 37/50\n",
      "10394/10394 [==============================] - 14s 1ms/sample - loss: 0.3357 - acc: 0.8893 - val_loss: 0.5937 - val_acc: 0.8379\n",
      "Epoch 38/50\n",
      "10394/10394 [==============================] - 14s 1ms/sample - loss: 0.3363 - acc: 0.8931 - val_loss: 0.6158 - val_acc: 0.8333\n",
      "Epoch 39/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.3020 - acc: 0.9034 - val_loss: 0.6175 - val_acc: 0.8402\n",
      "Epoch 40/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.3057 - acc: 0.9033 - val_loss: 0.6107 - val_acc: 0.8367\n",
      "Epoch 41/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.2811 - acc: 0.9090 - val_loss: 0.6283 - val_acc: 0.8367\n",
      "Epoch 42/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.2818 - acc: 0.9108 - val_loss: 0.6202 - val_acc: 0.8363\n",
      "Epoch 43/50\n",
      "10394/10394 [==============================] - 17s 2ms/sample - loss: 0.2843 - acc: 0.9091 - val_loss: 0.6003 - val_acc: 0.8383\n",
      "Epoch 44/50\n",
      "10394/10394 [==============================] - 18s 2ms/sample - loss: 0.2728 - acc: 0.9124 - val_loss: 0.6420 - val_acc: 0.8333\n",
      "Epoch 45/50\n",
      "10394/10394 [==============================] - 21s 2ms/sample - loss: 0.2853 - acc: 0.9109 - val_loss: 0.6141 - val_acc: 0.8363\n",
      "Epoch 46/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.2814 - acc: 0.9097 - val_loss: 0.6490 - val_acc: 0.8348\n",
      "Epoch 47/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.2683 - acc: 0.9150 - val_loss: 0.6226 - val_acc: 0.8402\n",
      "Epoch 48/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.2679 - acc: 0.9155 - val_loss: 0.7008 - val_acc: 0.8440\n",
      "Epoch 49/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.2602 - acc: 0.9194 - val_loss: 0.6301 - val_acc: 0.8417\n",
      "Epoch 50/50\n",
      "10394/10394 [==============================] - 15s 1ms/sample - loss: 0.2575 - acc: 0.9211 - val_loss: 0.7541 - val_acc: 0.8290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feaa83a17b8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_sub.fit(X_train_app, y_train, epochs=50, validation_data=(X_test_app, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_sub.to_json()\n",
    "with open(\"cnn_apparel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes = cnn_sub.predict_classes(X_test_app)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = np.nonzero(predicted_classes==y_true)[0]\n",
    "incorrect = np.nonzero(predicted_classes!=y_true)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 5, ..., 0, 5, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.95      0.98      0.96       368\n",
      "     Class 1       0.96      0.91      0.93       347\n",
      "     Class 2       0.90      0.55      0.68        96\n",
      "     Class 3       0.95      0.98      0.96        82\n",
      "     Class 4       0.98      0.93      0.95       135\n",
      "     Class 5       0.96      0.99      0.98      1591\n",
      "\n",
      "    accuracy                           0.96      2619\n",
      "   macro avg       0.95      0.89      0.91      2619\n",
      "weighted avg       0.96      0.96      0.96      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(6)]\n",
    "print(classification_report(y_true, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sub-Categories for Accessories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5586, 6)\n",
      "(1656, 6)\n"
     ]
    }
   ],
   "source": [
    "acc_train = df_train[df_train.masterCategory=='Accessories']\n",
    "acc_train_idx = list(acc_train.index)\n",
    "X_train_acc = X_train[acc_train_idx]\n",
    "\n",
    "acc_test = df_test[df_test.masterCategory=='Accessories']\n",
    "acc_test_idx = list(acc_test.index)\n",
    "X_test_acc = X_test[acc_test_idx]\n",
    "\n",
    "y_train_acc0 = acc_train.subCategory.copy().astype('category').cat.codes\n",
    "y_test_acc0 = acc_test.subCategory.copy().astype('category').cat.codes\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_acc = to_categorical(y_train_acc0)\n",
    "y_test_acc = to_categorical(y_test_acc0)\n",
    "\n",
    "print(y_train_acc.shape)\n",
    "print(y_test_acc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_acc = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_acc.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_acc.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_acc.add(Dropout(0.2))\n",
    "\n",
    "cnn_acc.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_acc.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_acc.add(Dropout(0.25))\n",
    "\n",
    "cnn_acc.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_acc.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "cnn_acc.add(Flatten())\n",
    "\n",
    "cnn_acc.add(Dense(128, activation='relu'))\n",
    "cnn_acc.add(Dropout(0.3))\n",
    "cnn_acc.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 2,977,158\n",
      "Trainable params: 2,977,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_acc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_acc.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5586 samples, validate on 1656 samples\n",
      "Epoch 1/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 5.3784 - acc: 0.7053 - val_loss: 0.2950 - val_acc: 0.8877\n",
      "Epoch 2/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.3736 - acc: 0.8813 - val_loss: 0.1463 - val_acc: 0.9589\n",
      "Epoch 3/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.2637 - acc: 0.9239 - val_loss: 0.2154 - val_acc: 0.9185\n",
      "Epoch 4/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.2196 - acc: 0.9338 - val_loss: 0.1077 - val_acc: 0.9716\n",
      "Epoch 5/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1816 - acc: 0.9440 - val_loss: 0.1520 - val_acc: 0.9662\n",
      "Epoch 6/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1455 - acc: 0.9552 - val_loss: 0.1314 - val_acc: 0.9668\n",
      "Epoch 7/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1347 - acc: 0.9603 - val_loss: 0.0842 - val_acc: 0.9819\n",
      "Epoch 8/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1180 - acc: 0.9662 - val_loss: 0.0910 - val_acc: 0.9789\n",
      "Epoch 9/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.0951 - acc: 0.9735 - val_loss: 0.0659 - val_acc: 0.9873\n",
      "Epoch 10/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.0908 - acc: 0.9701 - val_loss: 0.0688 - val_acc: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efe905dee48>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_acc.fit(X_train_acc, y_train_acc, epochs=10, validation_data=(X_test_acc, y_test_acc), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_acc = y_test_acc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes_acc = cnn_acc.predict_classes(X_test_acc)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = (predicted_classes_acc ==y_true_acc).to_numpy().nonzero()[0]\n",
    "incorrect = (predicted_classes_acc !=y_true_acc).to_numpy().nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.97      0.98       597\n",
      "     Class 1       1.00      1.00      1.00       213\n",
      "     Class 2       1.00      0.79      0.88        56\n",
      "     Class 3       0.93      0.98      0.96       230\n",
      "     Class 4       1.00      0.98      0.99        50\n",
      "     Class 5       0.97      0.99      0.98       510\n",
      "\n",
      "    accuracy                           0.98      1656\n",
      "   macro avg       0.98      0.95      0.96      1656\n",
      "weighted avg       0.98      0.98      0.98      1656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names_acc = [\"Class {}\".format(i) for i in range(6)]\n",
    "print(classification_report(y_true_acc, predicted_classes_acc, target_names=target_names_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_acc.to_json()\n",
    "with open(\"cnn_accessories.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sub-Categories for Footwear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6296, 3)\n",
      "(1796, 3)\n"
     ]
    }
   ],
   "source": [
    "fw_train = df_train[df_train.masterCategory=='Footwear']\n",
    "fw_train_idx = list(fw_train.index)\n",
    "X_train_fw = X_train[fw_train_idx]\n",
    "\n",
    "fw_test = df_test[df_test.masterCategory=='Footwear']\n",
    "fw_test_idx = list(fw_test.index)\n",
    "X_test_fw = X_test[fw_test_idx]\n",
    "\n",
    "y_train_fw0 = fw_train.subCategory.copy().astype('category').cat.codes\n",
    "y_test_fw0 = fw_test.subCategory.copy().astype('category').cat.codes\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_fw = to_categorical(y_train_fw0)\n",
    "y_test_fw = to_categorical(y_test_fw0)\n",
    "\n",
    "print(y_train_fw.shape)\n",
    "print(y_test_fw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fw = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_fw.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_fw.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_fw.add(Dropout(0.25))\n",
    "\n",
    "cnn_fw.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_fw.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_fw.add(Dropout(0.25))\n",
    "\n",
    "cnn_fw.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_fw.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_fw.add(Dropout(0.25))\n",
    "\n",
    "cnn_fw.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_fw.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "cnn_fw.add(Flatten())\n",
    "cnn_fw.add(Dense(512, activation='relu'))\n",
    "cnn_fw.add(Dropout(0.5))\n",
    "cnn_fw.add(Dense(128, activation='relu'))\n",
    "cnn_fw.add(Dropout(0.5))\n",
    "cnn_fw.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,976,771\n",
      "Trainable params: 2,976,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_fw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fw.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6296 samples, validate on 1796 samples\n",
      "Epoch 1/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.2411 - acc: 0.9096 - val_loss: 0.2692 - val_acc: 0.9059\n",
      "Epoch 2/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.2430 - acc: 0.9142 - val_loss: 0.2402 - val_acc: 0.9209\n",
      "Epoch 3/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.2186 - acc: 0.9196 - val_loss: 0.2267 - val_acc: 0.9259\n",
      "Epoch 4/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.2075 - acc: 0.9187 - val_loss: 0.2224 - val_acc: 0.9287\n",
      "Epoch 5/20\n",
      "1152/6296 [====>.........................] - ETA: 6s - loss: 0.1787 - acc: 0.9297"
     ]
    }
   ],
   "source": [
    "cnn_fw.fit(X_train_fw, y_train_fw, epochs=20, validation_data=(X_test_fw, y_test_fw), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_fw = y_test_fw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes_fw = cnn_fw.predict_classes(X_test_fw)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = (predicted_classes_fw ==y_true_fw).to_numpy().nonzero()[0]\n",
    "incorrect = (predicted_classes_fw !=y_true_fw).to_numpy().nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.97      0.98       597\n",
      "     Class 1       1.00      1.00      1.00       213\n",
      "     Class 2       1.00      0.79      0.88        56\n",
      "     Class 3       0.93      0.98      0.96       230\n",
      "     Class 4       1.00      0.98      0.99        50\n",
      "     Class 5       0.97      0.99      0.98       510\n",
      "\n",
      "    accuracy                           0.98      1656\n",
      "   macro avg       0.98      0.95      0.96      1656\n",
      "weighted avg       0.98      0.98      0.98      1656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names_fw = [\"Class {}\".format(i) for i in range(3)]\n",
    "print(classification_report(y_true_fw, predicted_classes_fw, target_names=target_names_fw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_fw.to_json()\n",
    "with open(\"cnn_footwear.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sub-Categories for Personal Care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6296, 3)\n",
      "(1796, 3)\n"
     ]
    }
   ],
   "source": [
    "pc_train = df_train[df_train.masterCategory=='Personal Care']\n",
    "pc_train_idx = list(pc_train.index)\n",
    "X_train_pc = X_train[pc_train_idx]\n",
    "\n",
    "pc_test = df_test[df_test.masterCategory=='Personal Care']\n",
    "pc_test_idx = list(pc_test.index)\n",
    "X_test_pc = X_test[pc_test_idx]\n",
    "\n",
    "y_train_pc0 = fw_train.subCategory.copy().astype('category').cat.codes\n",
    "y_test_pc0 = fw_test.subCategory.copy().astype('category').cat.codes\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_pc = to_categorical(y_train_pc0)\n",
    "y_test_pc = to_categorical(y_test_pc0)\n",
    "\n",
    "print(y_train_pc.shape)\n",
    "print(y_test_pc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pc = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_pc.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_pc.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_pc.add(Dropout(0.2)\n",
    "\n",
    "cnn_pc.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_pc.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_pc.add(Dropout(0.25)\n",
    "\n",
    "cnn_pc.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_pc.add(Dropout(0.4)\n",
    "           \n",
    "cnn_pc.add(Flatten()\n",
    "           \n",
    "cnn_pc.add(Dense(128, activation='relu'))\n",
    "cnn_pc.add(Dropout(0.3))\n",
    "cnn_pc.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,976,771\n",
      "Trainable params: 2,976,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_fw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fw.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6296 samples, validate on 1796 samples\n",
      "Epoch 1/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 5.0477 - acc: 0.7851 - val_loss: 0.7035 - val_acc: 0.7973\n",
      "Epoch 2/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.5417 - acc: 0.8135 - val_loss: 0.3989 - val_acc: 0.8190\n",
      "Epoch 3/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.4569 - acc: 0.8313 - val_loss: 0.3964 - val_acc: 0.8330\n",
      "Epoch 4/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.3950 - acc: 0.8523 - val_loss: 0.3420 - val_acc: 0.8803\n",
      "Epoch 5/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.3457 - acc: 0.8774 - val_loss: 0.3733 - val_acc: 0.8469\n",
      "Epoch 6/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.3220 - acc: 0.8809 - val_loss: 0.3126 - val_acc: 0.8959\n",
      "Epoch 7/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.2981 - acc: 0.8939 - val_loss: 0.2801 - val_acc: 0.9087\n",
      "Epoch 8/10\n",
      "2080/6296 [========>.....................] - ETA: 5s - loss: 0.3045 - acc: 0.8990"
     ]
    }
   ],
   "source": [
    "cnn_fw.fit(X_train_fw, y_train_fw, epochs=10, validation_data=(X_test_fw, y_test_fw), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_fw = y_test_fw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes_fw = cnn_fw.predict_classes(X_test_fw)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = (predicted_classes_fw ==y_true_fw).to_numpy().nonzero()[0]\n",
    "incorrect = (predicted_classes_fw !=y_true_fw).to_numpy().nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.97      0.98       597\n",
      "     Class 1       1.00      1.00      1.00       213\n",
      "     Class 2       1.00      0.79      0.88        56\n",
      "     Class 3       0.93      0.98      0.96       230\n",
      "     Class 4       1.00      0.98      0.99        50\n",
      "     Class 5       0.97      0.99      0.98       510\n",
      "\n",
      "    accuracy                           0.98      1656\n",
      "   macro avg       0.98      0.95      0.96      1656\n",
      "weighted avg       0.98      0.98      0.98      1656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names_fw = [\"Class {}\".format(i) for i in range(3)]\n",
    "print(classification_report(y_true_fw, predicted_classes_fw, target_names=target_names_fw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_fw.to_json()\n",
    "with open(\"cnn_footwear.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
