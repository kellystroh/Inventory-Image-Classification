{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "from tensorflow.keras import datasets, layers, models, regularizers, initializers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.io import imshow\n",
    "from skimage.transform import rotate\n",
    "from skimage.filters.edges import convolve\n",
    "\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "np.random.seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test_labels.csv')\n",
    "df_train = pd.read_csv('data/train_labels.csv')\n",
    "\n",
    "bw_loaded = np.load('data/bw_images.npz')\n",
    "X_train= bw_loaded['a']\n",
    "X_test = bw_loaded['b']\n",
    "\n",
    "X_test = X_test.reshape(-1,80,60,1)\n",
    "X_train = X_train.reshape(-1,80,60,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_functions import pick_ylabels, multi_index_counts, test_counts_by_cat, train_counts_by_cat, category_codes, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_ylabels(column):\n",
    "    y_train = df_train[column].copy().astype('category').cat.codes\n",
    "    y_test = df_test[column].copy().astype('category').cat.codes\n",
    "    return (y_train.values, y_test.values)\n",
    "def multi_index_counts(col, col2):\n",
    "    counts = df_test.groupby([col, col2]).count().id\n",
    "    return counts\n",
    "\n",
    "def category_codes(column):\n",
    "    _, ytest = pick_ylabels(column)\n",
    "    cat_codes = {}\n",
    "    cat_code_list = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = i\n",
    "        t = df_test[column].value_counts().index[i]\n",
    "        cat_codes[s] = t\n",
    "#         cat_code_list.append([s, t])\n",
    "\n",
    "#     for key in sorted(cat_codes):\n",
    "#         print(\"%s: %s\" % (key, cat_codes[key]))\n",
    "    return cat_codes\n",
    "\n",
    "def test_counts_by_cat(column):\n",
    "    _, ytest = pick_ylabels(column)\n",
    "    test_counts_dict = {}\n",
    "    test_counts = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = df_test[column].value_counts().values[i]\n",
    "        t = df_test[column].value_counts().index[i]\n",
    "        test_counts_dict[t] = s\n",
    "        test_counts.append([t, s])\n",
    "#     for i in sorted(test_counts):\n",
    "#         print(\"%s: %s\" % (test_counts[0], test_counts[1]))\n",
    "    return test_counts\n",
    "\n",
    "def train_counts_by_cat(column):\n",
    "    y_train = pick_ylabels(column)\n",
    "    train_counts_dict = {}\n",
    "    train_counts = []\n",
    "    for i in range(len(df_test[column].value_counts().index)):\n",
    "        s = df_train[column].value_counts().values[i]\n",
    "        t = df_train[column].value_counts().index[i]\n",
    "        train_counts_dict[t] = s\n",
    "        train_counts.append([t, s])\n",
    "#     for i in sorted(test_counts):\n",
    "#         print(\"%s: %s\" % (test_counts[0], test_counts[1]))\n",
    "    return train_counts\n",
    "\n",
    "def class_weights(column):\n",
    "    train_counts = train_counts_by_cat(column)\n",
    "    counts_list = []\n",
    "    ratio_list = []\n",
    "    ratio_dict = {}\n",
    "    for x in test_counts:\n",
    "        counts_list.append(x[1])\n",
    "    #print(counts_list)\n",
    "    z = sum(counts_list)\n",
    "    for x in counts_list:\n",
    "        if np.round(x/z, 3) ==0:\n",
    "            ratio_list.append(.001)\n",
    "        else: \n",
    "            ratio_list.append(np.round(x/z, 2))\n",
    "    for k, v in enumerate(ratio_list):\n",
    "        ratio_dict[k] = v\n",
    "    return ratio_dict\n",
    "\n",
    "def model_results(model, column):\n",
    "    yhat = model.predict(X_test)\n",
    "    _ , ytest = pick_ylabels(column)\n",
    "    accuracy = accuracy_score(ytest, yhat)\n",
    "    print( 'Accuracy Score: ', accuracy )\n",
    "    recall = recall_score(ytest, yhat, average='weighted')\n",
    "    print( 'Recall Score: ', recall)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    wrong_id_list = []\n",
    "    pred_cat_list = []\n",
    "    real_cat_list = []\n",
    "    for row_idx in range(len(ytest)):\n",
    "        if ytest[row_idx]!=yhat[row_idx]:\n",
    "            wrong_id_list.append(row_idx)\n",
    "            pred_cat_list.append(yhat[row_idx])\n",
    "            real_cat_list.append(ytest[row_idx])\n",
    "\n",
    "    arr = np.array([ real_cat_list, pred_cat_list])\n",
    "    arr = arr.transpose()\n",
    "    wrong_df = pd.DataFrame( arr, index= wrong_id_list, columns = ['actual', 'predicted'] )\n",
    "    return (accuracy, recall, wrong_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sub-Categories for Apparel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = df_train[df_train.masterCategory=='Apparel']\n",
    "app_train_idx = list(app_df_train.index)\n",
    "X_train_app = X_train[app_train_idx]\n",
    "\n",
    "app_test = df_test[df_test.masterCategory=='Apparel']\n",
    "app_test_idx = list(app_df_test.index)\n",
    "X_test_app = X_test[app_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train0 = app_train.subCategory.copy().astype('category').cat.codes\n",
    "y_test0 = app_test.subCategory.copy().astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train0)\n",
    "y_test = to_categorical(y_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9194, 6)\n",
      "(2619, 6)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_sub = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_sub.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_sub.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_sub.add(Dropout(0.2))\n",
    "\n",
    "cnn_sub.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_sub.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_sub.add(Dropout(0.25))\n",
    "\n",
    "cnn_sub.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "# cnn_sub.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_sub.add(Dropout(0.4))\n",
    "\n",
    "cnn_sub.add(Flatten())\n",
    "\n",
    "cnn_sub.add(Dense(128, activation='relu'))\n",
    "cnn_sub.add(Dropout(0.3))\n",
    "cnn_sub.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 2,977,158\n",
      "Trainable params: 2,977,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_sub.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sub.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9194 samples, validate on 2619 samples\n",
      "Epoch 1/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.1187 - acc: 0.9621 - val_loss: 0.1931 - val_acc: 0.9576\n",
      "Epoch 2/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.1083 - acc: 0.9670 - val_loss: 0.1886 - val_acc: 0.9553\n",
      "Epoch 3/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.1066 - acc: 0.9657 - val_loss: 0.1753 - val_acc: 0.9565\n",
      "Epoch 4/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.1180 - acc: 0.9636 - val_loss: 0.1741 - val_acc: 0.9569\n",
      "Epoch 5/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.1086 - acc: 0.9674 - val_loss: 0.1606 - val_acc: 0.9595\n",
      "Epoch 6/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.1063 - acc: 0.9655 - val_loss: 0.1770 - val_acc: 0.9515\n",
      "Epoch 7/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.1048 - acc: 0.9670 - val_loss: 0.1955 - val_acc: 0.9549\n",
      "Epoch 8/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0965 - acc: 0.9716 - val_loss: 0.2184 - val_acc: 0.9527\n",
      "Epoch 9/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0973 - acc: 0.9689 - val_loss: 0.1718 - val_acc: 0.9588\n",
      "Epoch 10/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0740 - acc: 0.9767 - val_loss: 0.1840 - val_acc: 0.9588\n",
      "Epoch 11/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0911 - acc: 0.9715 - val_loss: 0.1607 - val_acc: 0.9549\n",
      "Epoch 12/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0961 - acc: 0.9707 - val_loss: 0.1458 - val_acc: 0.9553\n",
      "Epoch 13/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0863 - acc: 0.9726 - val_loss: 0.1805 - val_acc: 0.9591\n",
      "Epoch 14/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0935 - acc: 0.9718 - val_loss: 0.1547 - val_acc: 0.9607\n",
      "Epoch 15/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0889 - acc: 0.9731 - val_loss: 0.1688 - val_acc: 0.9576\n",
      "Epoch 16/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.1345 - acc: 0.9625 - val_loss: 0.1692 - val_acc: 0.9580\n",
      "Epoch 17/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0968 - acc: 0.9726 - val_loss: 0.1854 - val_acc: 0.9576\n",
      "Epoch 18/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.1079 - acc: 0.9679 - val_loss: 0.2030 - val_acc: 0.9603\n",
      "Epoch 19/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0948 - acc: 0.9730 - val_loss: 0.1799 - val_acc: 0.9557\n",
      "Epoch 20/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0940 - acc: 0.9725 - val_loss: 0.1808 - val_acc: 0.9530\n",
      "Epoch 21/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0926 - acc: 0.9726 - val_loss: 0.2139 - val_acc: 0.9611\n",
      "Epoch 22/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0757 - acc: 0.9772 - val_loss: 0.2001 - val_acc: 0.9603\n",
      "Epoch 23/50\n",
      "9194/9194 [==============================] - 12s 1ms/sample - loss: 0.0709 - acc: 0.9759 - val_loss: 0.1741 - val_acc: 0.9618\n",
      "Epoch 24/50\n",
      "9194/9194 [==============================] - 12s 1ms/sample - loss: 0.0618 - acc: 0.9807 - val_loss: 0.1720 - val_acc: 0.9622\n",
      "Epoch 25/50\n",
      "9194/9194 [==============================] - 12s 1ms/sample - loss: 0.0694 - acc: 0.9792 - val_loss: 0.2079 - val_acc: 0.9569\n",
      "Epoch 26/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0651 - acc: 0.9810 - val_loss: 0.2244 - val_acc: 0.9622\n",
      "Epoch 27/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0783 - acc: 0.9747 - val_loss: 0.1921 - val_acc: 0.9633\n",
      "Epoch 28/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0738 - acc: 0.9774 - val_loss: 0.2287 - val_acc: 0.9588\n",
      "Epoch 29/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0676 - acc: 0.9822 - val_loss: 0.1961 - val_acc: 0.9630\n",
      "Epoch 30/50\n",
      "9194/9194 [==============================] - 12s 1ms/sample - loss: 0.0861 - acc: 0.9774 - val_loss: 0.2557 - val_acc: 0.9595\n",
      "Epoch 31/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0841 - acc: 0.9781 - val_loss: 0.2093 - val_acc: 0.9584\n",
      "Epoch 32/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0848 - acc: 0.9772 - val_loss: 0.1740 - val_acc: 0.9595\n",
      "Epoch 33/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0543 - acc: 0.9831 - val_loss: 0.1806 - val_acc: 0.9630\n",
      "Epoch 34/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0496 - acc: 0.9836 - val_loss: 0.1885 - val_acc: 0.9626\n",
      "Epoch 35/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0666 - acc: 0.9799 - val_loss: 0.1880 - val_acc: 0.9611\n",
      "Epoch 36/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0686 - acc: 0.9811 - val_loss: 0.2160 - val_acc: 0.9603\n",
      "Epoch 37/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0451 - acc: 0.9855 - val_loss: 0.2889 - val_acc: 0.9626\n",
      "Epoch 38/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.1285 - acc: 0.9670 - val_loss: 0.3847 - val_acc: 0.9049\n",
      "Epoch 39/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.1365 - acc: 0.9612 - val_loss: 0.2164 - val_acc: 0.9588\n",
      "Epoch 40/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0693 - acc: 0.9809 - val_loss: 0.2027 - val_acc: 0.9630\n",
      "Epoch 41/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0735 - acc: 0.9796 - val_loss: 0.2255 - val_acc: 0.9557\n",
      "Epoch 42/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0559 - acc: 0.9835 - val_loss: 0.2636 - val_acc: 0.9584\n",
      "Epoch 43/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0571 - acc: 0.9858 - val_loss: 0.1935 - val_acc: 0.9569\n",
      "Epoch 44/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0412 - acc: 0.9871 - val_loss: 0.2284 - val_acc: 0.9641\n",
      "Epoch 45/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0393 - acc: 0.9876 - val_loss: 0.2558 - val_acc: 0.9599\n",
      "Epoch 46/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0486 - acc: 0.9868 - val_loss: 0.2382 - val_acc: 0.9603\n",
      "Epoch 47/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0549 - acc: 0.9846 - val_loss: 0.2370 - val_acc: 0.9599\n",
      "Epoch 48/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0500 - acc: 0.9873 - val_loss: 0.1841 - val_acc: 0.9595\n",
      "Epoch 49/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0615 - acc: 0.9840 - val_loss: 0.2023 - val_acc: 0.9626\n",
      "Epoch 50/50\n",
      "9194/9194 [==============================] - 13s 1ms/sample - loss: 0.0444 - acc: 0.9875 - val_loss: 0.2577 - val_acc: 0.9626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efec4622828>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_sub.fit(X_train_app, y_train, epochs=50, validation_data=(X_test_app, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_sub.to_json()\n",
    "with open(\"cnn_apparel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes = cnn_sub.predict_classes(X_test_app)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = np.nonzero(predicted_classes==y_true)[0]\n",
    "incorrect = np.nonzero(predicted_classes!=y_true)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 5, ..., 0, 5, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.95      0.98      0.96       368\n",
      "     Class 1       0.96      0.91      0.93       347\n",
      "     Class 2       0.90      0.55      0.68        96\n",
      "     Class 3       0.95      0.98      0.96        82\n",
      "     Class 4       0.98      0.93      0.95       135\n",
      "     Class 5       0.96      0.99      0.98      1591\n",
      "\n",
      "    accuracy                           0.96      2619\n",
      "   macro avg       0.95      0.89      0.91      2619\n",
      "weighted avg       0.96      0.96      0.96      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(6)]\n",
    "print(classification_report(y_true, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sub-Categories for Accessories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5586, 6)\n",
      "(1656, 6)\n"
     ]
    }
   ],
   "source": [
    "acc_train = df_train[df_train.masterCategory=='Accessories']\n",
    "acc_train_idx = list(acc_train.index)\n",
    "X_train_acc = X_train[acc_train_idx]\n",
    "\n",
    "acc_test = df_test[df_test.masterCategory=='Accessories']\n",
    "acc_test_idx = list(acc_test.index)\n",
    "X_test_acc = X_test[acc_test_idx]\n",
    "\n",
    "y_train_acc0 = acc_train.subCategory.copy().astype('category').cat.codes\n",
    "y_test_acc0 = acc_test.subCategory.copy().astype('category').cat.codes\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_acc = to_categorical(y_train_acc0)\n",
    "y_test_acc = to_categorical(y_test_acc0)\n",
    "\n",
    "print(y_train_acc.shape)\n",
    "print(y_test_acc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_acc = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_acc.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_acc.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_acc.add(Dropout(0.2))\n",
    "\n",
    "cnn_acc.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_acc.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_acc.add(Dropout(0.25))\n",
    "\n",
    "cnn_acc.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_acc.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "cnn_acc.add(Flatten())\n",
    "\n",
    "cnn_acc.add(Dense(128, activation='relu'))\n",
    "cnn_acc.add(Dropout(0.3))\n",
    "cnn_acc.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 2,977,158\n",
      "Trainable params: 2,977,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_acc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_acc.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5586 samples, validate on 1656 samples\n",
      "Epoch 1/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 5.3784 - acc: 0.7053 - val_loss: 0.2950 - val_acc: 0.8877\n",
      "Epoch 2/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.3736 - acc: 0.8813 - val_loss: 0.1463 - val_acc: 0.9589\n",
      "Epoch 3/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.2637 - acc: 0.9239 - val_loss: 0.2154 - val_acc: 0.9185\n",
      "Epoch 4/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.2196 - acc: 0.9338 - val_loss: 0.1077 - val_acc: 0.9716\n",
      "Epoch 5/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1816 - acc: 0.9440 - val_loss: 0.1520 - val_acc: 0.9662\n",
      "Epoch 6/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1455 - acc: 0.9552 - val_loss: 0.1314 - val_acc: 0.9668\n",
      "Epoch 7/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1347 - acc: 0.9603 - val_loss: 0.0842 - val_acc: 0.9819\n",
      "Epoch 8/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.1180 - acc: 0.9662 - val_loss: 0.0910 - val_acc: 0.9789\n",
      "Epoch 9/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.0951 - acc: 0.9735 - val_loss: 0.0659 - val_acc: 0.9873\n",
      "Epoch 10/10\n",
      "5586/5586 [==============================] - 8s 1ms/sample - loss: 0.0908 - acc: 0.9701 - val_loss: 0.0688 - val_acc: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efe905dee48>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_acc.fit(X_train_acc, y_train_acc, epochs=10, validation_data=(X_test_acc, y_test_acc), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_acc = y_test_acc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes_acc = cnn_acc.predict_classes(X_test_acc)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = (predicted_classes_acc ==y_true_acc).to_numpy().nonzero()[0]\n",
    "incorrect = (predicted_classes_acc !=y_true_acc).to_numpy().nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.97      0.98       597\n",
      "     Class 1       1.00      1.00      1.00       213\n",
      "     Class 2       1.00      0.79      0.88        56\n",
      "     Class 3       0.93      0.98      0.96       230\n",
      "     Class 4       1.00      0.98      0.99        50\n",
      "     Class 5       0.97      0.99      0.98       510\n",
      "\n",
      "    accuracy                           0.98      1656\n",
      "   macro avg       0.98      0.95      0.96      1656\n",
      "weighted avg       0.98      0.98      0.98      1656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names_acc = [\"Class {}\".format(i) for i in range(6)]\n",
    "print(classification_report(y_true_acc, predicted_classes_acc, target_names=target_names_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_acc.to_json()\n",
    "with open(\"cnn_accessories.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sub-Categories for Footwear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6296, 3)\n",
      "(1796, 3)\n"
     ]
    }
   ],
   "source": [
    "fw_train = df_train[df_train.masterCategory=='Footwear']\n",
    "fw_train_idx = list(fw_train.index)\n",
    "X_train_fw = X_train[fw_train_idx]\n",
    "\n",
    "fw_test = df_test[df_test.masterCategory=='Footwear']\n",
    "fw_test_idx = list(fw_test.index)\n",
    "X_test_fw = X_test[fw_test_idx]\n",
    "\n",
    "y_train_fw0 = fw_train.subCategory.copy().astype('category').cat.codes\n",
    "y_test_fw0 = fw_test.subCategory.copy().astype('category').cat.codes\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_fw = to_categorical(y_train_fw0)\n",
    "y_test_fw = to_categorical(y_test_fw0)\n",
    "\n",
    "print(y_train_fw.shape)\n",
    "print(y_test_fw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fw = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_fw.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_fw.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_fw.add(Dropout(0.2))\n",
    "\n",
    "# cnn_fw.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "# cnn_fw.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# cnn_fw.add(Dropout(0.25))\n",
    "\n",
    "cnn_fw.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_fw.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_fw.add(Dropout(0.2))\n",
    "\n",
    "cnn_fw.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_fw.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "cnn_fw.add(Flatten())\n",
    "# cnn_fw.add(Dense(512, activation='relu'))\n",
    "# cnn_fw.add(Dropout(0.5))\n",
    "cnn_fw.add(Dense(128, activation='relu'))\n",
    "cnn_fw.add(Dropout(0.3))\n",
    "cnn_fw.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,976,771\n",
      "Trainable params: 2,976,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_fw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fw.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6296 samples, validate on 1796 samples\n",
      "Epoch 1/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 3.0283 - acc: 0.7910 - val_loss: 0.6067 - val_acc: 0.7873\n",
      "Epoch 2/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.5435 - acc: 0.8040 - val_loss: 0.4611 - val_acc: 0.7873\n",
      "Epoch 3/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.4477 - acc: 0.8051 - val_loss: 0.4000 - val_acc: 0.8151\n",
      "Epoch 4/20\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.4062 - acc: 0.8159 - val_loss: 0.3760 - val_acc: 0.8302\n",
      "Epoch 5/20\n",
      "1888/6296 [=======>......................] - ETA: 7s - loss: 0.3952 - acc: 0.8294"
     ]
    }
   ],
   "source": [
    "cnn_fw.fit(X_train_fw, y_train_fw, epochs=20, validation_data=(X_test_fw, y_test_fw), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_fw = y_test_fw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes_fw = cnn_fw.predict_classes(X_test_fw)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = (predicted_classes_fw ==y_true_fw).to_numpy().nonzero()[0]\n",
    "incorrect = (predicted_classes_fw !=y_true_fw).to_numpy().nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.79      0.86      0.82       184\n",
      "     Class 1       0.91      0.78      0.84       198\n",
      "     Class 2       0.97      0.98      0.98      1414\n",
      "\n",
      "    accuracy                           0.95      1796\n",
      "   macro avg       0.89      0.87      0.88      1796\n",
      "weighted avg       0.95      0.95      0.95      1796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names_fw = [\"Class {}\".format(i) for i in range(3)]\n",
    "print(classification_report(y_true_fw, predicted_classes_fw, target_names=target_names_fw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_fw.to_json()\n",
    "with open(\"cnn_footwear.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sub-Categories for Personal Care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6296, 3)\n",
      "(1796, 3)\n"
     ]
    }
   ],
   "source": [
    "pc_train = df_train[df_train.masterCategory=='Personal Care']\n",
    "pc_train_idx = list(pc_train.index)\n",
    "X_train_pc = X_train[pc_train_idx]\n",
    "\n",
    "pc_test = df_test[df_test.masterCategory=='Personal Care']\n",
    "pc_test_idx = list(pc_test.index)\n",
    "X_test_pc = X_test[pc_test_idx]\n",
    "\n",
    "y_train_pc0 = fw_train.subCategory.copy().astype('category').cat.codes\n",
    "y_test_pc0 = fw_test.subCategory.copy().astype('category').cat.codes\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_pc = to_categorical(y_train_pc0)\n",
    "y_test_pc = to_categorical(y_test_pc0)\n",
    "\n",
    "print(y_train_pc.shape)\n",
    "print(y_test_pc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pc = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxPool reduces dimensionality of each feature\n",
    "#Dropout to reduce overfitting\n",
    "\n",
    "cnn_pc.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80,60,1)))\n",
    "cnn_pc.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_pc.add(Dropout(0.2)\n",
    "\n",
    "cnn_pc.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_pc.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_pc.add(Dropout(0.25)\n",
    "\n",
    "cnn_pc.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_pc.add(Dropout(0.4)\n",
    "           \n",
    "cnn_pc.add(Flatten()\n",
    "           \n",
    "cnn_pc.add(Dense(128, activation='relu'))\n",
    "cnn_pc.add(Dropout(0.3))\n",
    "cnn_pc.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 78, 58, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 16, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               2883712   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,976,771\n",
      "Trainable params: 2,976,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_fw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fw.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6296 samples, validate on 1796 samples\n",
      "Epoch 1/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 5.0477 - acc: 0.7851 - val_loss: 0.7035 - val_acc: 0.7973\n",
      "Epoch 2/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.5417 - acc: 0.8135 - val_loss: 0.3989 - val_acc: 0.8190\n",
      "Epoch 3/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.4569 - acc: 0.8313 - val_loss: 0.3964 - val_acc: 0.8330\n",
      "Epoch 4/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.3950 - acc: 0.8523 - val_loss: 0.3420 - val_acc: 0.8803\n",
      "Epoch 5/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.3457 - acc: 0.8774 - val_loss: 0.3733 - val_acc: 0.8469\n",
      "Epoch 6/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.3220 - acc: 0.8809 - val_loss: 0.3126 - val_acc: 0.8959\n",
      "Epoch 7/10\n",
      "6296/6296 [==============================] - 9s 1ms/sample - loss: 0.2981 - acc: 0.8939 - val_loss: 0.2801 - val_acc: 0.9087\n",
      "Epoch 8/10\n",
      "2080/6296 [========>.....................] - ETA: 5s - loss: 0.3045 - acc: 0.8990"
     ]
    }
   ],
   "source": [
    "cnn_fw.fit(X_train_fw, y_train_fw, epochs=10, validation_data=(X_test_fw, y_test_fw), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_fw = y_test_fw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes_fw = cnn_fw.predict_classes(X_test_fw)\n",
    "\n",
    "# get the indices to be plotted\n",
    "correct = (predicted_classes_fw ==y_true_fw).to_numpy().nonzero()[0]\n",
    "incorrect = (predicted_classes_fw !=y_true_fw).to_numpy().nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.97      0.98       597\n",
      "     Class 1       1.00      1.00      1.00       213\n",
      "     Class 2       1.00      0.79      0.88        56\n",
      "     Class 3       0.93      0.98      0.96       230\n",
      "     Class 4       1.00      0.98      0.99        50\n",
      "     Class 5       0.97      0.99      0.98       510\n",
      "\n",
      "    accuracy                           0.98      1656\n",
      "   macro avg       0.98      0.95      0.96      1656\n",
      "weighted avg       0.98      0.98      0.98      1656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names_fw = [\"Class {}\".format(i) for i in range(3)]\n",
    "print(classification_report(y_true_fw, predicted_classes_fw, target_names=target_names_fw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fitted model\n",
    "model_json = cnn_fw.to_json()\n",
    "with open(\"cnn_footwear.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
